{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/planet-understanding-the-amazon-from-space/train_v2.csv')\n",
    "labels = df['tags'].str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "l = mlb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after getting the structure let's write a custom PyTorch Dataset \n",
    "# setitem and len are required by the parent class\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skimage import io\n",
    "from torchvision import transforms\n",
    "\n",
    "class AmazonDataset(Dataset):\n",
    "\n",
    "    def __init__(self, file_name, filepath='../input/planet-understanding-the-amazon-from-space', transforms=None):\n",
    "        \"\"\"\n",
    "        read the file and lazy load the images in getitem\n",
    "        transforms: torchvision.transform.Compose\n",
    "        \"\"\"\n",
    "        # headers = image_name, tags\n",
    "        self.path = filepath\n",
    "        self.datapath = os.path.join(self.path, '')\n",
    "        self.image_df = pd.read_csv(os.path.join(self.path, file_name))\n",
    "        self.X_train = self.image_df['image_name']\n",
    "        # tags are space delimited\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.y_train = self.mlb.fit_transform(self.image_df['tags'].str.split(' ')).astype('float')\n",
    "        self.classes = list(self.mlb.classes_)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        return the length of the training set\n",
    "        \"\"\"\n",
    "        return len(self.image_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        return the corresponding image and labels\n",
    "        returns a tuple(image_tensor, label_tensor)\n",
    "        \"\"\"\n",
    "        img_path = os.path.join(self.path, 'train-jpg', self.X_train.iloc[idx])\n",
    "        image = io.imread(img_path + '.jpg')\n",
    "        labels = torch.from_numpy(self.y_train[idx,:]).float()\n",
    "        if transforms:\n",
    "            image = self.transforms(image)\n",
    "        return image, labels\n",
    "    \n",
    "    def label_dist(self, prop=False):\n",
    "        tags = dataset.image_df['tags'].str.split(' ').to_list()\n",
    "        tags = [items for tag in tags for items in tag]\n",
    "        self.labels, self.counts = np.unique(tags, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "        transforms.Resize(32),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "dataset = AmazonDataset(file_name='train_v2.csv', transforms=transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset,\n",
    "                          batch_size=256,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4 # 1 for CUDA\n",
    "                         # pin_memory=True # CUDA only\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg16\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.vgg = vgg16(pretrained=True)\n",
    "        self.vgg = nn.Sequential(*list(self.vgg.children())[:-1])\n",
    "        \n",
    "        self.fc1 = nn.Linear(25088, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 17)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.vgg(x)\n",
    "        x = x.view(-1, np.prod(x.size()[1:]))\n",
    "        x = F.dropout(F.relu(self.fc1(x)))\n",
    "        x = F.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return F.sigmoid(x)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "model = Model()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, freeze=None, unfreeze=None):\n",
    "    model.train()\n",
    "    \n",
    "    # \n",
    "    if freeze is not None:\n",
    "        freeze = freeze*2\n",
    "        for param in list(model.parameters())[:-freeze]:\n",
    "            param.requires_grad = False\n",
    "    if unfreeze:\n",
    "        for param in list(model.parameters()):\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        for a, (x, y) in enumerate(train_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x)\n",
    "            loss = F.binary_cross_entropy(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if a % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    i, a * len(x), len(train_loader.dataset),\n",
    "                    100. * a / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the accuracy on the train set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(train_loader):\n",
    "        if i!=1:\n",
    "            images, labels = data\n",
    "            images, lables = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            print(outputs.data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            print(predicted)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 40479 train images: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
